[["index.html", "Sticky Pi, a high-frequency smart insect trap to study daily activity in the field Introduction", " Sticky Pi, a high-frequency smart insect trap to study daily activity in the field Quentin Geissmann 2021-02-16 Introduction The principle behind Sticky Pis Sticky Pis are smart sticky traps using a Raspberry Pi camera to automatically score when, which and where insects were captured (using modern AI tools). They take very frequent pictures (three per hour), which reveals much more information compared to traditional traps (such as insects' response to weather fluctuations and effect of the time of the day). Sticky Pis integrate into a scalable platform, where individual devices send their data to a centralised web-server. A single team can deploy multiple devices and compile large ecological datasets. The Sticky Pi project is a community open-source academic resource. They are affordable and can be easily adapted for research, teaching and applied for work. If you use Sticky Pis in your research, please cite our publication. "],["overview.html", "Platform Overview", " Platform Overview The Sticky Pi project contains several interconnected tools. A github organisation features the material (source code, data, CAD files, ...) for each individual tool. Here is a list of all the tools: Name Description sticky-pi-device The Hardware and software for the Sticky Pi cameras (i.e. device) sticky-pi-device-v2 The improved version of the smart traps (in development) sticky-pi-api Server and client api and the docker services for the server webapps sticky-pi-ml Machine learning for the Sticky Pi project sticky-pi-manuscript Manuscipt material and experiments for the 2021 method publication sticky-pi.github.io Source code of this documentation TODO include image here: platform. A clickable svg would be great This is an overview of the main components of the platform. The details of each part will be explain further. Hardware Sticky Pi devices -- Takes pictures of traps and record environmental conditions Data harvester -- Manages devices and retrieve their data (in the field) Web server Database -- Stores image metadata as well as, processing results, users... S3 server -- Store and serve image data and ML models API -- Parses client requests to put/get resources from the underlying database Webapp -- A frontend website to visualise/plot the images taken and processing results Nginx server -- Secures and rout connections between above services and to the outside world Analysis pipeline -- Pre-processes images in real time Machine Learning Universal Insect Detector -- Detects insect vs background, in all images Siamese Insect Matcher -- Tracks insect instances across imaged Insect Tuboid Classifier -- Predictss insect taxonomy from a tracked instance "],["hardware.html", "Hardware Device Data harvester", " Hardware This page describes and explains how to build the two main components of the hardware: the Sticky Pi Device and the Data Harvester. Briefly, multiple Sticky Pis are deployed in the field. Each device stores its images on its own SD card. On a regular basis (e.g. weekly), experimenters use a data harvester to retrieve the data from multiple devices. Silently, the data harvester also syncs the location and time of the devices it communicates with. One Data Harvester may be used to maintain multiple traps. Multiple Data Harvesters can exist in the same platform (e.g. five experimenters, one harvester per experimenter, ten devices per experimenter). This section involve familiarity with 3D printing, electronics, DIY, ... We are working on streamlining the assembly process towards a more off-the-shelf tool, but are generally happy to collaborate and help building devices -- do not hesitate to contact us. Device Overview Figure 1: Sticky Pi Device As you can see in Figure 1, the device has two main parts, which are connected with a ribbon cable: the camera box and the light box. A complete description of the parts, price and reference is available in our Bill of Material Note that all 3D-printed parts are available on our onshape repository where they can be exported in a variety of formats. Assembly Camera Box and light box can be assembled separately and swapped between devices (i.e. the light box acts as a plug and play module for the camera box). Camera box Figure 2: Needed parts for the camera box Burn our OS image onto the SD card (note you can also make your own from scratch image by adaptingthe scripts in). Danger Zone! Ensure you know what you are doing here. In particular, give the path to the correct drive otherwise you may wipe out the wrong drive, and lose data. On Unix-like systems, use lsblk to see all drives. To burn an SD card use our script like sh burn_image.sh -i &lt;PATH_TO_LOCAL_IMAGE&gt; -d &lt;DEVICE&gt;, where &lt;PATH_TO_LOCAL_IMAGE&gt; is the OS image you just downloaded, and &lt;DEVICE&gt; the SD card location e.g. /dev/mmcblk0 -- you need etcher-cli. Prepare the Raspberry Pi. Figure 3: Modifications to the Raspberry Pi Zero Solder 2x5 headers for the Real Time Clock on pins 1-10. Mount the clock (Figure 3A). Solder directly the IDC right angle connector onto the board on pins 35-40 (Figure 3A). On the back of the Raspberry pi board, use a jumper cable to solder GPIO pin 40 to +5V (this provides power to the Pi, Figure 3B) Figure 4: Mounting the Raspberry Pi on the sledge Use four screws to mount the pi on the &quot;Pi sledge&quot;. Plug the ribbon cable for the camera (Figure 4A). Fold the ribbon cable around the sledge as in the picture, and mount the camera with another four screws (Figure 4B-C) Insert the OS SD card (burnt as described above) Focus the camera. For those who want to assemble multiple devices, we recommend a &quot;camera focusing station&quot; that can adapt a Pi sledge and has a display, keyboard... This way, one can use raspivid in preview mode to check focus and alignment. Initialize your device (you can do that at the same time as focusing), which you can do with the Data harvester: Power the data harvester, and ensure the time is set (not it is in GMT/UTC). Plug it to the pi's USB port. Boot/power the pi. The data harvester should then display information, including the unique ID of the pi. It will be an eight-digit hexadecimal number (e.g. abcd0123). Make a couple of physical label with this tag and stick them to the box (and write them on the sledge). As part of the communication process, the clock of the raspberry pi will be updated (indeed the factory RTC is unset) Thread the 1x6 ribbon cable (it should be at least 50cm long) through the &quot;camera box&quot; before clamping the 2x3 IDC connector on each side. You want have the two connectors in the same orientation (i.e. a wire connect pin 1 of the left connector to pin 1 o the right connector -- and not pin 6): Plug the ITC connector on the Pi GPIO, and gently slide the Pi sledge inside the camera box, while pulling the slack cable from the outside. Note, at the stage, you can also add some desiccant inside the box to reduce fogging. Assemble the &quot;camera box lid&quot;: Figure 5: Assembly of the camera box lid Cut a glass microscope slide into a 25x25mm square with a glass cutter (e.g. with a 3d printed gauge and snaping tool and tool it takes just a few seconds, Figure 5A-C). Place the glass window on the slot, use masking tape or duct tape to cover the central area and the back. Cast a layer of epoxy resin, and let it set for a day this will embed the glass in the lid. Note that it makes sense to make multiple lids at the same time and avoid wasting time and epoxy (Figure 5D-E). Clean the lid. Optionally coat it with water repellent such as Rain-X Add calk at the junction between the lid and the box, screw the lid on the box. Also use calk to seal the 6x1 ribbon cable outlet. Coat the whole box with a layer of epoxy (note you can also chose to do that before assembly) Light box Needed parts for the light box Assemble our custom PCB: Figure 6: Assembly of the custom PCB Manufacture/order the PCB from the gerber files (Figure 6A) Prepare the timer (scratch the board to disable the built-in potentiometer) -- (red in Figure 6B). Solder all parts to the board. This should be fairly self explanatory from the labels (Figure 6C). Make a custom connection to our push button (red in Figure 6C). This is arguably a bit of a hack, but that allows us to mimic the built-in TLP5110 push button, with our own. Thread the push button (before soldering it, not to twist the cables) Screw the PCB to the bottom of the light box (be careful not to split the material, do not hesitate to use shorter screw). Figure 7: Assembly of the custom PCB Insert the battery connector (Figure 7A) Screw the Humidity and temperature sensor to the outside the box (Figure 7A-B). Glue the solar panel in the top slot Assemble the light diffuser: Figure 8: Assembly of the custom PCB Cut six 5V, white, led light strips (Figure 8A). On one side, cut away the + pad, and the - on the other side. Align all the + pads on the top, and solder them together, in parallel, with a transverse wire Solder the 1x2 header to be connected to our PCB as in the picture (the male pins will be protruding downward). Use superglue to glue the header to the diffuser (Figure 8B). Test setup: Connect a camera box, using the 1x6 cable. Plug the light diffuser (or just a placeholder 5v LED light for now). Plug a battery. You should see the LED of the timer glowing (if not, press the push button to force reset the timer). After less than a minute, the The flash should be triggered, and the timer should shut down. Pressing the push button should restart the whole process. If left untouched, this should happen every 20min, approximately. QC and troubleshooting Controlling the assembly before deployment in the field will save you a lot of trouble. A few suggestions: Plug all devices, and press the push button to initiate the image acquisition. Ensure all devices flash. The light should blink twice. If the light does not blink. Check power/timer/light connection If the light blinks more than twice, the device is reporting an error. Typically, the camera cannot be found. Plug the Data Harvester and boot a device you want to test. Data transfer should be initiated. Check the label of the pi matches the ID displayed by the harvester. Monitor image transfer. Once all devices have been harvested, retrieve the memory stick of the harvester and inspect the content. There should be one directory for each device Each directory contains all the pictures for this device and a log file Open the log file to check no errors were reported The name of each image contains the time in UTC. Ensure the time is correct. Open the images to check exposure, focus,... The environmental data (temperature, relative humidity, GPS coordinates and other meta variables) are encoded in the exif metadata inside the &quot;Make&quot; field (Sometime, though rarely, the temperature/humidity sensor fails, so you may have missing values). Use Data harvester "],["web-server.html", "Web Server Github repository Hosting Configuration and important files", " Web Server This page describes and explains how to deploy and maintain the web server. As much as we try to streamline this process, deploying our web server on the cloud does require some familiarity with Unix/Linux systems, Docker. We are open for collaboration and may be able to help you deploy you server, so do not hesitate to contact us. As described in the overview, it contains these key components: * Database -- Stores image metadata as well as, processing results, users... * S3 server -- Store and serve image data and ML models * API -- Parses client requests to put/get resources from the underlying database * Webapp -- A frontend website to visualise/plot the images taken and processing results * Nginx server -- Secures and rout connections between above services and to the outside world. Here is a schematics of how these services interact: TODO. Github repository The all the source code needed for deployement can be found on the sticky-pi-api github repository. It contains two important subdirectories: src, a python package used to create the API, and server, a set of docker services orchestrated with docker compose. For deployment, we only care about the server -- if you are interested, the API is documented on readthedoc, but it should only concern you if you want to take part in development. Hosting The simplest way to deploy the Sticky Pi server stack is on a remote Linux virtual machine. Perhaps your institudion provides some cloud hosting, for instance [Compute Canada Cloud](https://www.computecanada.ca/research-portal/national-services/compute-canada-cloud/, or you can opt for a commercial cloud provider. You can also decide to run the server on a custom machine within a restricted network. Configuration and important files Within the server directory, there are a few noticeable files we will describe: deploy.sh -- A script you can run to deploy the whole stack. More details later. docker-compose.yml -- The base docker-compose configuration file. docker-compose.prod.yml -- The specification of the above file, for production. .env -- An overall configuration file defining. You will need to modify some variables in it. .secret.env -- Contains credentials. For security reasons, this file does not exist yet you need to create it. Do not share this file, and ensure the permissions are restrictive. .env file You need to create a directory that will contain all the server data (except the s3-hosted files). Set LOCAL_VOLUME_ROOT in the .env file accordingly: LOCAL_VOLUME_ROOT=/your/root/dirctory. In order to encrypt data flow between client and server, we enforce https. That implies the registration of a domain name. Typically, you want to: 1. Ensure your cloud provider can provide a static/floating IP address for your instance, say 111.112.113.114. 1. Find a DNS provider and register your domain name, say sticky.net. 1. Use your DNS provider to create two A records: sticky.net -&gt; 111.112.113.114 and *.sticky.net -&gt; 111.112.113.114 1. Define ROOT_DOMAIN_NAME in the .env file to your registered domain name. E.g. ROOT_DOMAIN_NAME=sticky.net .secret.env file Create or add to .secret.env file the variables by modifiying this template: # En encryption key can be any long sting of ascii characters, # e.g. something like `cfbewif7y8rfy4w3aNIKFW9Yfh89HFN9` SECRET_API_KEY= # Your S3 host. We will describe further the difference between # external and local S3 provider # For local option we can set # S3_HOST=s3.${ROOT_DOMAIN_NAME} # for remote option this would be a hostname like `my-s3.provider.com` S3_HOST= # For local s3 option, you want to define arbitrary keys: # e.g. S3_ACCESS_KEY=fnwfnoAEVikenAV and # S3_PRIVATE_KEY=cfweavb87eabv8uehabv98hwAW7 # For remote option, you will need to issue a key pair and paste it S3_ACCESS_KEY= S3_PRIVATE_KEY= MYSQL_PASSWORD= API_ADMIN_PASSWORD= ADMIN_EMAIL= S3_BUCKET_NAME= UID_PASSWORD= "],["ml.html", "Machine Learning", " Machine Learning todo "],["community.html", "Issues and community Citation Having troubles Contributing Contact", " Issues and community Citation Sticky Pis are a research tool. As such, they are -- and will always be -- as free and open-source as possible. If you use Sticky Pis as part of your research, please cite our reference publication. Having troubles If you are having issues or you want help with something, the best thing you can do is fill an &quot;issue&quot; on the github repository of the relevant tool. Contributing We welcome external contributions and hope Sticky Pis develops as part of a computational entomology community. There are several ways you can contribute: By requesting features and reporting bugs through the github issue system By sending pull requests to preexisting tools By volunteering to maintain/develop a tools Contact Sticky Pis are developed at the [Plant-Insect Ecology and Evolution lab] at UBC, Vancouver(https://lfs-carrillo.sites.olt.ubc.ca/) in collaboration with the Haney Lab and the Insect Biocontrol lab. Do not hesitate to contact Quentin Geissmann, the main contributor of the project for inquiries. "]]
